#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
remove.py â€” note ç”¨ Markdown ã‚¯ãƒªãƒ¼ãƒŠãƒ¼ ï¼‹ 3 åˆ†å‰²å‡ºåŠ›
ï¼ˆã‚¿ã‚¤ãƒˆãƒ«å…ˆé ­ã® # ãƒãƒ¼ã‚¯å‰Šé™¤å¯¾å¿œç‰ˆï¼‰
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â— å‡ºåŠ›ã‚’ 1 ãƒ•ã‚¡ã‚¤ãƒ« â†’ 3 ãƒ•ã‚¡ã‚¤ãƒ«ã¸åˆ†å‰²
   â”œ hashtags.txt : è‡ªå‹•ç”Ÿæˆã—ãŸãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°åˆ—
   â”œ title.txt    : æœ€åˆã® Markdown è¦‹å‡ºã—è¡Œï¼ˆ# â€¦ï¼‰â€»# ã¯é™¤å»
   â”” body.txt     : ã‚¿ã‚¤ãƒˆãƒ«ä»¥é™ã®æœ¬æ–‡ï¼‹ãƒ‡ã‚£ã‚¹ã‚¯ãƒ¬ãƒ¼ãƒãƒ¼
â— æ—§ output.txt ã¯ç”Ÿæˆã—ãªã„
â— ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’çœç•¥å¯
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""

import os
import sys
import re
import shutil
from datetime import datetime

import webbrowser          # ãƒ–ãƒ©ã‚¦ã‚¶èµ·å‹•
import pyperclip           # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰æ“ä½œ
import time 


# -------------------------------------------------------------
# 0  HTML ãƒ©ã‚¤ã‚¯ãªãƒšã‚¢ã‚¿ã‚° <tag>â€¦</tag> ã®è§’æ‹¬å¼§ã ã‘é™¤å»
# -------------------------------------------------------------
HTML_PAIR = re.compile(r"<([A-Za-z][A-Za-z0-9]*)\b[^>]*>(.*?)</\1>", re.DOTALL)

def strip_html_pairs(text: str) -> str:
    prev = None
    while prev != text:
        prev = text
        text = HTML_PAIR.sub(lambda m: m.group(2), text)
    return text

# -------------------------------------------------------------
# 1  è¦‹å‡ºã—è¡Œå†…ã® **bold** ã‚’é™¤å»
# -------------------------------------------------------------
HEADING_BOLD_LINE = re.compile(r"^(?P<prefix>[ \t]*#+\s*)(?P<body>.*)$", re.MULTILINE)
BOLD_INLINE = re.compile(r'\*\*([^"\n]*?)\*\*')

def strip_bold_in_headings(text: str) -> str:
    def _repl(match):
        prefix, body = match.group('prefix'), match.group('body')
        body_clean = BOLD_INLINE.sub(r"\1", body)
        return f"{prefix}{body_clean}"
    return HEADING_BOLD_LINE.sub(_repl, text)

# -------------------------------------------------------------
# 2  ã‹ã£ã“å‰Šé™¤ï¼ˆå¼•ç”¨ï¼URLï¼[] ã‚’å«ã‚€ã‚‚ã®ï¼‰
# -------------------------------------------------------------
PAREN_PATTERN = re.compile(r"\s*\([^)]*(?:\[[^\]]+]|https?://)[^)]*\)")

def clean_parentheses(text: str) -> str:
    text = PAREN_PATTERN.sub('', text)
    text = re.sub(r"\s*\(\s*\)", '', text)
    text = re.sub(r"\)\s*(?=[ã€‚ã€ï¼Œâ€¦\.\,\)]|\n|$)", '', text)
    return re.sub(r"[ \t]{2,}", ' ', text)

# -------------------------------------------------------------
# 3 '**   xxx   **' â†’ '**xxx**'
# -------------------------------------------------------------
INNER_BOLD = re.compile(r"\*\*[\s\u3000]*([^\*]+?)[\s\u3000]*\*\*")

def strip_inner_spaces(text: str) -> str:
    return INNER_BOLD.sub(lambda m: f"**{m.group(1)}**", text)

# -------------------------------------------------------------
# 4 '**xxx**' ã‚’å‰å¾Œ 1 ç©ºç™½ã«åŒ…ã‚€
# -------------------------------------------------------------
def pad_bold_uniformly(text: str) -> str:
    text = re.sub(r"\*\*([^\*]+?)\*\*", r" **\1** ", text)
    text = re.sub(r" *\n", '\n', text)
    text = re.sub(r"\n *", '\n', text)
    return text

# -------------------------------------------------------------
# 5 è¡Œé€”ä¸­ã® '## ' ã‚’è¦‹å‡ºã—åŒ–
# -------------------------------------------------------------
def ensure_heading_newline(text: str) -> str:
    return re.sub(r"\n(?!\n)(##\s+)", r"\n\n\1", text)

# -------------------------------------------------------------
# 6 å‰æ›¸ãã‚’å‰Šé™¤
# -------------------------------------------------------------
def drop_preamble(text: str) -> str:
    m = re.search(r"(?m)^[ \t]*#+\s", text)
    return text[m.start():] if m else text

# -------------------------------------------------------------
# 2a  ãƒãƒƒã‚¯ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ä»˜ã '**' ã‚’æ­£è¦ '**' ã«æˆ»ã™
# -------------------------------------------------------------
def unescape_bold(text: str) -> str:
    return text.replace(r"\*\*", "**")

# -------------------------------------------------------------
# 7 æ–‡ç« ä¸­ã®ã€ŒXæœˆXæ—¥æ™‚ç‚¹ã€ã‚’ä»Šæ—¥ã«ç½®æ›
# -------------------------------------------------------------
AS_OF_PATTERN = re.compile(r"[0-9ï¼-ï¼™]{1,2}æœˆ[0-9ï¼-ï¼™]{1,2}æ—¥æ™‚ç‚¹")

def update_as_of_date(text: str) -> str:
    today = datetime.now()
    today_str = f"{today.month}æœˆ{today.day}æ—¥æ™‚ç‚¹"
    return AS_OF_PATTERN.sub(today_str, text)

# -------------------------------------------------------------
# ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
# -------------------------------------------------------------
def clean_text(raw: str) -> str:
    txt = drop_preamble(raw)
    txt = unescape_bold(txt)
    txt = strip_html_pairs(txt)
    txt = strip_bold_in_headings(txt)
    txt = update_as_of_date(txt)
    txt = clean_parentheses(txt)
    txt = strip_inner_spaces(txt)
    txt = pad_bold_uniformly(txt)
    txt = ensure_heading_newline(txt)
    return txt.rstrip('\n') + '\n'

# -------------------------------------------------------------
# ä¼æ¥­åãƒ»ã‚¿ã‚°é–¢é€£ï¼ˆãƒ•ãƒ«ãƒªã‚¹ãƒˆï¼‰
# -------------------------------------------------------------
COMPANIES = [
    'ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Š','ã‚½ãƒ‹ãƒ¼ã‚°ãƒ«ãƒ¼ãƒ—','æ±äº¬ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ³','ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯ã‚°ãƒ«ãƒ¼ãƒ—','ä»»å¤©å ‚',
    'ä¸‰è±UFJFG','ä¸‰è±UFJ','ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆãƒªãƒ†ã‚¤ãƒªãƒ³ã‚°','ãƒ¦ãƒ‹ãƒ»ãƒãƒ£ãƒ¼ãƒ ','æ­¦ç”°è–¬å“å·¥æ¥­','ä¸‰è±å•†äº‹',
    'æœ¬ç”°æŠ€ç ”å·¥æ¥­','ã‚­ãƒ¼ã‚¨ãƒ³ã‚¹','SUMCO','æ—¥æœ¬é›»ä¿¡é›»è©±','NTT','ãƒãƒ³ãƒ€ã‚¤ãƒŠãƒ ã‚³HD',
    'ä¸‰äº•ä½å‹FG','ä¸‰äº•ä½å‹ãƒ•ã‚£ãƒŠãƒ³ã‚·ãƒ£ãƒ«ã‚°ãƒ«ãƒ¼ãƒ—','ã‚»ãƒ–ãƒ³ï¼†ã‚¢ã‚¤HD','èŠ±ç‹','ã‚¢ã‚¹ãƒ†ãƒ©ã‚¹è£½è–¬','ä¸‰äº•ç‰©ç”£',
    'æ—¥ç”£è‡ªå‹•è»Š','æ—¥ç«‹è£½ä½œæ‰€','ãƒ«ãƒã‚µã‚¹ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹','KDDI','ã‚«ãƒ—ã‚³ãƒ³',
    'ã¿ãšã»FG','ã‚¤ã‚ªãƒ³','ã‚­ãƒªãƒ³HD','ç¬¬ä¸€ä¸‰å…±','ä¼Šè—¤å¿ å•†äº‹','ã‚¹ã‚ºã‚­','ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯HD',
    'ã‚¢ãƒ‰ãƒãƒ³ãƒ†ã‚¹ãƒˆ','ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯','ã‚¹ã‚¯ã‚¦ã‚§ã‚¢ãƒ»ã‚¨ãƒ‹ãƒƒã‚¯ã‚¹HD','ã‚ªãƒªãƒƒã‚¯ã‚¹','PPIH',
    'ã‚¢ã‚µãƒ’ã‚°ãƒ«ãƒ¼ãƒ—HD','ã‚¨ãƒ¼ã‚¶ã‚¤','ä½å‹å•†äº‹','ãƒãƒ„ãƒ€','NEC','ä¿¡è¶ŠåŒ–å­¦å·¥æ¥­','ãƒ¡ãƒ«ã‚«ãƒª',
    'ã‚³ãƒŠãƒŸã‚°ãƒ«ãƒ¼ãƒ—','ç¬¬ä¸€ç”Ÿå‘½HD','ãƒ­ãƒ¼ã‚½ãƒ³','ã‚µãƒƒãƒãƒ­HD','ä¸­å¤–è£½è–¬','ä¸¸ç´…','SUBARU',
    'å¯Œå£«é€š','ãƒ•ã‚¡ãƒŠãƒƒã‚¯','ã‚µã‚¤ãƒãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ','ã‚³ãƒ¼ã‚¨ãƒ¼ãƒ†ã‚¯ãƒ¢HD','æ±äº¬æµ·ä¸ŠHD',
    'ä¸‰è¶Šä¼Šå‹¢ä¸¹HD','ã‚µãƒ³ãƒˆãƒªãƒ¼é£Ÿå“','å¡©é‡ç¾©è£½è–¬','è±Šç”°é€šå•†','ä¸‰è±è‡ªå‹•è»Šå·¥æ¥­',
    'ã‚­ãƒ¤ãƒãƒ³','æ‘ç”°è£½ä½œæ‰€','LY','é‡æ‘HD','J.ãƒ•ãƒ­ãƒ³ãƒˆãƒªãƒ†ã‚¤ãƒªãƒ³ã‚°','æ—¥æ¸…é£Ÿå“HD',
    'å¤§å¡šHD','ã‚³ãƒãƒ„','ã„ã™ã‚è‡ªå‹•è»Š','ãƒ‹ã‚³ãƒ³','ãƒ‡ã‚£ãƒ¼ãƒ»ã‚¨ãƒŒãƒ»ã‚¨ãƒ¼','SBIãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹',
    'è‰¯å“è¨ˆç”»','å‘³ã®ç´ ','å°é‡è–¬å“å·¥æ¥­','ãƒ€ã‚¤ã‚­ãƒ³å·¥æ¥­','ãƒ¤ãƒãƒç™ºå‹•æ©Ÿ','ä¸‰è±é›»æ©Ÿ','ã‚ŠããªHD',
    'ZOZO','ã‚­ãƒƒã‚³ãƒ¼ãƒãƒ³','æ—¥æœ¬æ–°è–¬','å®‰å·é›»æ©Ÿ','æ—¥é‡è‡ªå‹•è»Š','ã‚†ã†ã¡ã‚‡éŠ€è¡Œ','ãƒ„ãƒ«ãƒHD',
    'ã‚«ãƒ«ãƒ“ãƒ¼','JCRãƒ•ã‚¡ãƒ¼ãƒ','ä¸‰è±é‡å·¥æ¥­','æ—¥æœ¬å–å¼•æ‰€ã‚°ãƒ«ãƒ¼ãƒ—','æ˜æ²»HD','JRæ±æ—¥æœ¬',
    'å¤§å’Œè¨¼åˆ¸G','ãƒ¤ã‚¯ãƒ«ãƒˆæœ¬ç¤¾','ANAãƒ›ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ³ã‚°ã‚¹','æ—¥æœ¬éƒµæ”¿','æ±äº¬é›»åŠ›HD',
    'ä¸‰äº•ä½å‹ãƒˆãƒ©ã‚¹ãƒˆHD','æ¥½å¤©éŠ€è¡Œ'
]

DISCLAIMER = (
    "â€»æœ¬è¨˜äº‹ã¯éŠ˜æŸ„ã«é–¢ã™ã‚‹æƒ…å ±ã‚’ã‚‚ã¨ã«åˆ†æã‚’è¡Œã£ãŸã‚‚ã®ã§ã‚ã‚Šã€"
    "ç‰¹å®šã®æŠ•è³‡è¡Œå‹•ã‚’æ¨å¥¨ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
    "æŠ•è³‡ã«é–¢ã™ã‚‹æœ€çµ‚çš„ãªåˆ¤æ–­ã¯ã€ã”è‡ªèº«ã®è²¬ä»»ã«ã¦ãŠé¡˜ã„ã„ãŸã—ã¾ã™ã€‚"
)

HASH_TAGS = (
    "#æ ªå¼æŠ•è³‡ #æ ª #æ ªä¾¡ #æ¥­ç¸¾ #æŠ•è³‡ #éŠ˜æŸ„åˆ†æ #è³‡ç”£é‹ç”¨ #æ–°NISA #NISA #çµŒæ¸ˆ #ä¼æ¥­"
)

def detect_company(text: str) -> str:
    earliest_pos = len(text) + 1
    selected = 'ãã®ä»–'
    for name in COMPANIES:
        pos = text.find(name)
        if pos != -1 and (pos < earliest_pos or (pos == earliest_pos and len(name) > len(selected))):
            earliest_pos = pos
            selected = name
            if earliest_pos == 0:
                break
    return selected

def build_hashtags(company: str) -> str:
    return HASH_TAGS + (f" #{company}" if company != "ãã®ä»–" else "")

# -------------------------------------------------------------
# å‡ºåŠ› & ãƒ­ã‚°ä¿å­˜
# -------------------------------------------------------------
def save_outputs_and_logs(in_path: str,
                          out_dir : str,
                          hashtags: str,
                          title   : str,
                          body    : str,
                          raw     : str) -> None:
    os.makedirs(out_dir, exist_ok=True)

    files = {
        'hashtags.txt': hashtags,
        'title.txt'   : title,
        'body.txt'    : body,
    }
    for fname, content in files.items():
        with open(os.path.join(out_dir, fname), 'w', encoding='utf-8') as f:
            f.write(content)

    company = detect_company(body)
    ts = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_dir = os.path.join('log', f'{ts}_{company}')
    os.makedirs(log_dir, exist_ok=True)

    shutil.copy2(in_path, os.path.join(log_dir, 'input.txt'))
    for fname in files:
        shutil.copy2(os.path.join(out_dir, fname),
                     os.path.join(log_dir, fname))

# -------------------------------------------------------------
# ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ & note æ–°è¦è¨˜äº‹ã‚¿ãƒ–ã‚’é–‹ã
# -------------------------------------------------------------
def copy_to_clipboard_sequence(title: str, hashtags: str, body: str) -> None:
    seq = [title, hashtags, body]
    for item in seq:
        pyperclip.copy(item)
        # macOS: 0.5ç§’ã€Windows: 1ç§’ãã‚‰ã„ä½™è£•ãŒã‚ã‚‹ã¨å®‰å¿ƒ
        time.sleep(0.5)


# -------------------------------------------------------------
# ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
# -------------------------------------------------------------
def main(in_path: str, out_dir: str) -> None:
    if not os.path.exists(in_path):
        raise FileNotFoundError(in_path)

    with open(in_path, encoding="utf-8") as f:
        raw = f.read()

    company   = detect_company(raw)
    hashtags  = build_hashtags(company) + '\n'
    cleaned   = clean_text(raw)

    first_nl   = cleaned.find('\n')
    title_line = cleaned[:first_nl].rstrip() if first_nl != -1 else cleaned.rstrip()
    title_line = re.sub(r'^[ \t]*#+\s*', '', title_line)      # â† # ã‚’é™¤å»

    body_part  = cleaned[first_nl+1:].lstrip('\n') if first_nl != -1 else ''
    body_text  = f"{body_part.rstrip()}\n\n{DISCLAIMER}\n"    # â† body ã¯æ”¹è¡Œã‚ã‚Šã§ OK

    # â˜… ã“ã“ã§æœ«å°¾æ”¹è¡Œã‚’è½ã¨ã—ã¦ãŠã
    hashtags_no_nl = hashtags.rstrip('\n')
    title_no_nl    = title_line           # æœ«å°¾æ”¹è¡Œã¯ä»˜ã‘ãªã„

    save_outputs_and_logs(
        in_path, out_dir,
        hashtags_no_nl,                  # â† æ”¹è¡Œãªã—
        title_no_nl,                     # â† æ”¹è¡Œãªã—
        body_text,
        raw
    )
    print(f"âœ” å‡ºåŠ›å…ˆ: {out_dir}\nâœ” ãƒ­ã‚°ä¿å­˜å®Œäº†")
    
	# æ—¢å­˜ã®ãƒ­ã‚°ä¿å­˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    print(f"âœ” å‡ºåŠ›å…ˆ: {out_dir}\nâœ” ãƒ­ã‚°ä¿å­˜å®Œäº†")

    # ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ä¸‰æ®µã‚³ãƒ”ãƒ¼ï¼‹ãƒ–ãƒ©ã‚¦ã‚¶ã§ note ã‚’é–‹ã
    copy_to_clipboard_sequence(title_line, hashtags_no_nl, body_text)
    webbrowser.open_new_tab("https://note.com/notes/new")
    print("ğŸ“‹ ã‚¿ã‚¤ãƒˆãƒ« â†’ ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚° â†’ æœ¬æ–‡ ã®é †ã«ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã¸ã‚³ãƒ”ãƒ¼æ¸ˆã¿")
    print("ãƒ–ãƒ©ã‚¦ã‚¶ã§æ–°è¦è¨˜äº‹ã‚¿ãƒ–ãŒé–‹ãã¾ã—ãŸã€‚ã‚¨ãƒ‡ã‚£ã‚¿ã§ 3 å›è²¼ã‚Šä»˜ã‘ã‚Œã°å®Œæˆã§ã™ï¼")


# -------------------------------------------------------------
# ã‚¹ã‚¯ãƒªãƒ—ãƒˆç›´æ¥å®Ÿè¡Œ
# -------------------------------------------------------------
if __name__ == "__main__":
    args = sys.argv[1:]

    input_path = 'input.txt'
    output_dir = 'output'

    if len(args) == 1:
        input_path = args[0]
    elif len(args) == 2:
        input_path, out_arg = args
        if out_arg.lower().endswith('.txt') or (os.path.exists(out_arg) and os.path.isfile(out_arg)):
            output_dir = os.path.splitext(out_arg)[0]  # output.txt â†’ output/
        else:
            output_dir = out_arg
    elif len(args) > 2:
        print("Usage:\n"
              "  python remove.py                 # input.txt â†’ ./output/\n"
              "  python remove.py <in>            # <in>     â†’ ./output/\n"
              "  python remove.py <in> <out>      # <in>     â†’ <out_dir|derived>/")
        sys.exit(1)

    main(input_path, output_dir)
